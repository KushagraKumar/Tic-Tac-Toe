{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING DEPENDENCIES\n",
    "import numpy as np\n",
    "LENGTH = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODING THE ENVIRONMENT\n",
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((LENGTH,LENGTH))\n",
    "        self.x = -1\n",
    "        self.o = 1\n",
    "        self.winner = None\n",
    "        self.ended = False\n",
    "        self.num_states = 3 ** (LENGTH*LENGTH)\n",
    "        \n",
    "    def is_empty(self,i,j):\n",
    "        return self.board[i,j] == 0\n",
    "    \n",
    "    def reward(self,sym):\n",
    "        # no reward until game is over\n",
    "            if not self.game_over():\n",
    "              return 0\n",
    "\n",
    "            # if we get here, game is over\n",
    "            # sym will be self.x or self.o\n",
    "            return 1 if self.winner == sym else 0\n",
    "        \n",
    "    def get_state(self):\n",
    "        h = 0\n",
    "        k = 0\n",
    "        \n",
    "        for i in range(LENGTH):\n",
    "            for j in range(LENGTH):\n",
    "                if self.board[i,j] == 0:\n",
    "                    v = 0\n",
    "                elif self.board[i,j] == self.x:\n",
    "                    v = 1\n",
    "                elif self.board[i,j] == self.o:\n",
    "                    v = 2\n",
    "                    \n",
    "                h = h + (3 ** k) * v\n",
    "                k = k + 1\n",
    "        return h\n",
    "                \n",
    "    def game_over(self,force_recalculate = False):\n",
    "        if not force_recalculate and self.ended:\n",
    "            return self.ended\n",
    "        \n",
    "        # CHECK FOR SUM IN ROW\n",
    "        for i in range(LENGTH):\n",
    "            for j in (self.x,self.o):\n",
    "                if self.board[i].sum() == j * LENGTH:\n",
    "                    self.winner = j\n",
    "                    self.ended = True\n",
    "                    return True\n",
    "        \n",
    "        # CHECK IF THE COLUMN IS SUM\n",
    "        for i in range(LENGTH):\n",
    "            for j in (self.x,self.o):\n",
    "                if self.board[:,i].sum() == j * LENGTH:\n",
    "                    self.winner = j\n",
    "                    self.ended = True\n",
    "                    return True\n",
    "        \n",
    "        # CHECK FOR DIAGONALS\n",
    "        for player in (self.x,self.o):\n",
    "            # MAIN DIAGONAL\n",
    "            if self.board.trace() == player * LENGTH :\n",
    "                self.winner = player\n",
    "                self.ended = True\n",
    "                return True\n",
    "                \n",
    "            # ANTI - DIAGONAL\n",
    "            if np.fliplr(self.board).trace() == player * LENGTH:\n",
    "                self.winner = player\n",
    "                self.ended = True\n",
    "                return True\n",
    "            \n",
    "        # CHECK FOR A DRAW\n",
    "        if np.all((self.board == 0) == False) :\n",
    "            self.winner = None\n",
    "            self.ended = True\n",
    "            return True\n",
    "        \n",
    "        # GAME IS NOT OVER YET\n",
    "        self.winner = None\n",
    "        return False\n",
    "    \n",
    "    def draw_board(self):\n",
    "        for i in range(LENGTH):\n",
    "            print(\"------------\\n\",end = '')\n",
    "            for j in range(LENGTH):\n",
    "                print(\"  \",end='')\n",
    "                if self.board[i,j] == self.x:\n",
    "                    print(\"x   |\",end = '')\n",
    "                elif self.board[i,j] == self.o:\n",
    "                    print(\"o   |\",end = '')\n",
    "                else:\n",
    "                    print(\"__  |\",end='')\n",
    "            print(\"\\n\")\n",
    "        print(\"------------\",end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def  __init__(self, eps=0.1, alpha=0.5):\n",
    "        self.eps = eps # probability of choosing random action instead of greedy\n",
    "        self.alpha = alpha # learning rate\n",
    "        self.verbose = False\n",
    "        self.state_history = []\n",
    "  \n",
    "  def setV(self, V):\n",
    "    self.V = V\n",
    "\n",
    "  def set_symbol(self, sym):\n",
    "    self.sym = sym\n",
    "\n",
    "  def set_verbose(self, v):\n",
    "    # if true, will print values for each position on the board\n",
    "    self.verbose = v\n",
    "\n",
    "  def reset_history(self):\n",
    "    self.state_history = []\n",
    "\n",
    "  def take_action(self, env):\n",
    "    # choose an action based on epsilon-greedy strategy\n",
    "    r = np.random.rand()\n",
    "    best_state = None\n",
    "    if r < self.eps:\n",
    "      # take a random action\n",
    "      if self.verbose:\n",
    "        print(\"Taking a random action\")\n",
    "\n",
    "      possible_moves = []\n",
    "      for i in range(LENGTH):\n",
    "        for j in range(LENGTH):\n",
    "          if env.is_empty(i, j):\n",
    "            possible_moves.append((i, j))\n",
    "      idx = np.random.choice(len(possible_moves))\n",
    "      next_move = possible_moves[idx]\n",
    "    else:\n",
    "      # choose the best action based on current values of states\n",
    "      # loop through all possible moves, get their values\n",
    "      # keep track of the best value\n",
    "      pos2value = {} # for debugging\n",
    "      next_move = None\n",
    "      best_value = -1\n",
    "      for i in range(LENGTH):\n",
    "        for j in range(LENGTH):\n",
    "          if env.is_empty(i, j):\n",
    "            # what is the state if we made this move?\n",
    "            env.board[i,j] = self.sym\n",
    "            state = env.get_state()\n",
    "            env.board[i,j] = 0 # don't forget to change it back!\n",
    "            pos2value[(i,j)] = self.V[state]\n",
    "            if self.V[state] > best_value:\n",
    "              best_value = self.V[state]\n",
    "              best_state = state\n",
    "              next_move = (i, j)\n",
    "\n",
    "      # if verbose, draw the board w/ the values\n",
    "      if self.verbose:\n",
    "        print(\"Taking a greedy action\")\n",
    "        for i in range(LENGTH):\n",
    "          print(\"------------------\")\n",
    "          for j in range(LENGTH):\n",
    "            if env.is_empty(i, j):\n",
    "              # print the value\n",
    "              print(\" %.2f|\" % pos2value[(i,j)], end=\"\")\n",
    "            else:\n",
    "              print(\"  \", end=\"\")\n",
    "              if env.board[i,j] == env.x:\n",
    "                print(\"x  |\", end=\"\")\n",
    "              elif env.board[i,j] == env.o:\n",
    "                print(\"o  |\", end=\"\")\n",
    "              else:\n",
    "                print(\"   |\", end=\"\")\n",
    "          print(\"\")\n",
    "        print(\"------------------\")\n",
    "\n",
    "    # make the move\n",
    "    env.board[next_move[0], next_move[1]] = self.sym\n",
    "\n",
    "  def update_state_history(self, s):\n",
    "    # cannot put this in take_action, because take_action only happens\n",
    "    # once every other iteration for each player\n",
    "    # state history needs to be updated every iteration\n",
    "    # s = env.get_state() # don't want to do this twice so pass it in\n",
    "    self.state_history.append(s)\n",
    "\n",
    "  def update(self, env):\n",
    "    reward = env.reward(self.sym)\n",
    "    target = reward\n",
    "    for prev in reversed(self.state_history):\n",
    "      value = self.V[prev] + self.alpha*(target - self.V[prev])\n",
    "      self.V[prev] = value\n",
    "      target = value\n",
    "    self.reset_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Human:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_symbol(self,sym):\n",
    "        self.symbol = sym\n",
    "        \n",
    "    def take_action(self,env):\n",
    "        while True:\n",
    "            # BREAK UNDER A VALID MOVE\n",
    "            move = input(\"Enter the coordinates for your move: (i,j = 0..2)\")\n",
    "            i,j = move.split(',')\n",
    "            i = int(i)\n",
    "            j = int(j)\n",
    "            \n",
    "            if env.isEmpty(i,j) :\n",
    "                env.board[i,j] = self.symbol\n",
    "                break\n",
    "                \n",
    "    def update_state_history(self,s):\n",
    "        pass\n",
    "    \n",
    "    def update(self,env):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state_hash_and_winner(env,i=0,j=0):\n",
    "    result = []\n",
    "    \n",
    "    for v in (0,env.x,env.o):\n",
    "        env.board[i,j] = v\n",
    "        \n",
    "        if j == 2:\n",
    "            if i == 2:\n",
    "                state = env.get_state()\n",
    "                ended = env.game_over(force_recalculate=True)\n",
    "                winner = env.winner\n",
    "                \n",
    "                result.append((state,winner,ended))\n",
    "            else :\n",
    "                result += get_state_hash_and_winner(env,i+1,0)\n",
    "        else:\n",
    "            result += get_state_hash_and_winner(env,i,j+1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZING THE VALUE ARRAY AT THE START\n",
    "def initialV_x(env, state_winner_triples) :\n",
    "    v = np.zeros(env.num_states)\n",
    "    for state,winner,ended in state_winner_triples:\n",
    "        if ended :\n",
    "            if winner == env.x :\n",
    "                v[state] = 1\n",
    "            else :\n",
    "                v[state] = 0\n",
    "        else :\n",
    "             v[state] = 0.5\n",
    "    \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialV_o(env, state_winner_triples) :\n",
    "    v = np.zeros(env.num_states)\n",
    "    for state,winner,ended in state_winner_triples :\n",
    "        if ended :\n",
    "            if winner == env.o :\n",
    "                v[state] = 1\n",
    "            else :\n",
    "                v[state] = 0\n",
    "        else :\n",
    "            v[state] = 0.5\n",
    "            \n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(p1,p2,env,draw = False) :\n",
    "    # LOOP UNTIL THE GAME IS OVER\n",
    "    current_player = None\n",
    "    while not env.game_over():\n",
    "        # SWITCH PLACES\n",
    "        if current_player == p1 :\n",
    "            current_player = p2\n",
    "        else :\n",
    "            current_player = p1\n",
    "            \n",
    "        # DRAWING THE BOARD FOR THE PLAYER PLAYING\n",
    "        if draw :\n",
    "            if draw == 1 and current_player == p1:\n",
    "                env.draw_board()\n",
    "            if draw == 2 and current_player == p2:\n",
    "                env.draw_board()\n",
    "                \n",
    "        # Current player takes his turn\n",
    "        current_player.take_action(env)\n",
    "        \n",
    "        # State histories get updated\n",
    "        state = env.get_state()\n",
    "        p1.update_state_history(state)\n",
    "        p2.update_state_history(state)\n",
    "        \n",
    "        \n",
    "    if draw :\n",
    "        env.draw_board()\n",
    "        \n",
    "    p1.update(env)\n",
    "    p2.update(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "Taking a greedy action\n",
      "------------------\n",
      " 0.61| 0.55| 0.68|\n",
      "------------------\n",
      " 0.62| 0.88| 0.66|\n",
      "------------------\n",
      " 0.51| 0.43| 0.68|\n",
      "------------------\n",
      "------------\n",
      "  __  |  __  |  __  |\n",
      "\n",
      "------------\n",
      "  __  |  x   |  __  |\n",
      "\n",
      "------------\n",
      "  __  |  __  |  __  |\n",
      "\n",
      "------------"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    p1 = Agent()\n",
    "    p2 = Agent()\n",
    "\n",
    "    env = Environment()\n",
    "    state_winner_triples = get_state_hash_and_winner(env)\n",
    "\n",
    "    vx = initialV_x(env,state_winner_triples)\n",
    "    p1.setV(vx)\n",
    "\n",
    "    vo = initialV_o(env,state_winner_triples)\n",
    "    p2.setV(vo)\n",
    "\n",
    "    p1.set_symbol(env.x)\n",
    "    p2.set_symbol(env.o)\n",
    "\n",
    "    # AGENT 1 AND 2 PLAY WITH EACH OTHER 10,000 TIMES\n",
    "    # TO LEARN \n",
    "    \n",
    "    T = 10000\n",
    "    for i in range(T):\n",
    "        if i%100 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        play_game(p1,p2,Environment())\n",
    "\n",
    "    human = Human()\n",
    "    human.set_symbol(env.o)\n",
    "    \n",
    "    while True :\n",
    "        p1.set_verbose(True)\n",
    "\n",
    "        play_game(p1,human,Environment(),draw=2)\n",
    "        answer = input(\"Play again? [Y/n]: \")\n",
    "        if answer and answer.lower()[0] == 'n':\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
